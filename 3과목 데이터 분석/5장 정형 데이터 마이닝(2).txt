3과목 데이터 분석
5장. 정형 데이터 마이닝


>>> [ 모형 평가 방법 (holdout, cross validation, bootstrap) ] 14:50

* 홀드아웃(Hold Out)
	- 원천 데이터를 랜덤하게 두 분류로 분리하여 교차검정을 실시하는 방법으로 하나는 모형 학습 및 구축을 위한 훈련용 자료로 다른 하나는 성과 평가를 위한 검증용 자료로 사용하는 방법
	- 과적합 발생 여부를 확인하기 위해서 주어진 데이터릐 일정부분을 모델로 만드는 훈련 데이터로 사용하고, 나머지 데이터를 사용해 모델을 평가
	- 잘못된 가설을 가정하게 되는 2종 오류의 발생을 방지
	- idx <- sample(2, nrow(iris), replace=True, prob=c(0.7, 0.3))
		=> iris 데이터를 7:3 비율로 나누어 Training에서 70%, Testing에 30% 사용하도록 하는 것

* 교차검증(Cross Validation)
	- 데이터가 충분하지 않을 경우 Hold-Out으로 나누면 많은 양의 분산 발생
	- 이에 대한 해결책으로 교차검증을 사용할 수 있음, 그러나 클래스 불균형 데이터에는 적합하지 않음
	* 클래스 불균형 : 데이터의 출력값이 한쪽에 몰려있는 경우를 말한다. (90%/10%)
	- 주어진 데이터를 가지고 반복적으로 성과를 측정하여 그 결과를 평균한 것으로 분류 분석 모형의 평가 방법

	* k-fold Cross Validation
		1) 전체 데이터를 shuffle
		2) k개로 데이터를 분할
		3) k번째의 하부 집합을 검증용 자료, k-1개는 훈련용 자료로 사용하여 k번 반복 측정
		4) 그 결과를 평균 낸 값을 최종 평가로 사용함

* 붓스트랩(bootstrap)
	- 평가를 반복하는 측면에서 교차검증과 유사하지만, 훈련용 자료를 반복 재선정한다는 점에서 차이가 있는 평가 방법
	- 붓스트랩은 관측지를 한 번 이상 훈련용 자료로 사용하는 복원추출법에 기반함
	- 전체 데이터 양이 크지 않을 경우의 모형 평가에 가장 적합
	- 훈련데이터를 63.2% 사용하는 0.632붓스트랩이 있음

* 데이터 분할 시 고려사항
	- class의 비율이 한쪽에 치우쳐 있는 클래스 불균형 상태라면 다음 기법 사용을 고려한다
		> under sampling : 적은 class의 수에 맞추는 것
		> over sampling : 많은 class의 수에 맞추는 것

 


>>> [ 오분류표 ] 21:40

* 오분류표를 활용한 평가 지표
-------------------------------------------
		| 예측(귀무가설, H0)	
구분		---------------------------
		| TRUE		| FALSE
-------------------------------------------
실제	| TRUE	| TP		| FN(2종 오류)
	-----------------------------------
(판정)	| FALSE	| FP(1종 오류)	| TN
-------------------------------------------

* Accuracy : (TP+TN) / (TP+TN+FP+FN)
	- 모델의 성능이 실제로 좋지 못하더라고 정확도가 높을 수 있음
* Error Rate : (FP+FN) / (TP+TN+FP+FN)
* Precision : TP / (TP+FP) [정밀도]
	=> 예측이 모두 TRUE의 경우
	- 
* Sensitivity, Recall : TP / (TP+FN) [민감도, 재현율]
	=> 판정이 모두 TRUE인 경우 (채택)
* 실 Sen, 예 Pre

* F1 Score = 2 * (Precision * Recall) / (Precision + Recall)
	- F1 Score는 불균형한 데이터 평가에 사용
	- 정밀도와 재현율을 조화평균, 정밀도와 재현율에 같은 가중치를 부여하여 평가한 지표

* Specificity [특이도] TN / (TN+FP)
	- 실제로 N(=False)인 것들 중 예측이 N으로 된 경우의 비율



>>> [ 오분류표 문제풀이 ] 9:49
* 정분류율(accuracy) : (TP + TN) / (TP + TN + FP[1종오류] + FN[2종오류] )
* 오분류율(error rate)
* F1 = 2 * ( Precision * Recall ) / ( Precision + Recall )
	=> Precision = ( 100 / 110 ) Recall[재현률] = ( 100/ 105 )
	=> TP / ( TP + FP ) [ 예측 T ]	TP / ( TP + FN ) [ 사실  T ]

Q. 오분류표의 평가지표 중 F2의 의미는?
	A. 재현율(Recall)에 정밀도(Precision)의 2배 만큼 가중치를 부여

* 정밀도(Precision) : TP / ( TP + FP )
	- 예측 값이 True인 것에 대해 실제 값이 True인 지표
* 재현율, 민감도(Recall, Sensitivity) : TP / ( TP + FN )
	- 실제 값이 True인 것이 대해 예측 값이 True인 지표
* F1 Score = 2 * (Precision * Recall) / (Precision + Recall)
* 정확도, 정분류율(Accuracy)
* F2 Score 
	- F 뒤의 숫자는 재현율에 부여하는 가중치를 주는 방식
	- 재현율에 정밀도의 2배 만큼 가중치를 부여하는 것
* 특이도(Specificity) 
	- 실제로 N(=False) 인 것들 중 예측이 N으로 된 경우의 비율
	- TN / ( TN + FP ) 
* FP Rate 1-특이도
	- 실제가 N인데 예측이 P로 된 비율(Y가 아닌데 Y호 예측된 비율, 1종 오류 비율)
	- FP / ( FP + TN )




>>> [ ROC Curve, Lift Table, Lift Chart ] 9:54

* ROC(Receiver Operating Characteristic) Curve
	- x축 : Fasle positive rate (1-Specificity) -> 1종 오류
		- 0의 값을 갖는 것이 좋다
	- y축 : True positive rate(Sensitivity) -> 올바르다
		- 1의 값을 갖는 것이 좋다
	- perfect classifier : 긍정, 부정 모두 다 맞추는 위치로 분류 성능이 우수하다고 봄
		-> x=0, y=1인 경우

	- X축은 FP Rate, Y축은 민감도를 나타내 이 두 평가 값의 관계로 모형을 평가함
	- ROC 그래프의 밑부분의 면적(AUC, Area Under the Curve)이 넓을수록 좋은 모형으로 평가함

		예측
		참 	거짓
사실 	참	TP	FN
	거짓	FP	TN
(TP + TN ) / all
(FP + FN) / all
TP / (TP+FN) -> Recall
TP / (TP+FP) -> Precition
FN / (FN+TN)	
TN / (FN+TN)

* 분류 모형 성능 평가 - Lift Table(이익 도표)
	- 분류 모형의 예측 성능을 평가하기 위한 척도, 주로 불균형 데이터 집합에 사용됨
	- 랜덤 모델과 비교하여 해당 분류 모델의 성과가 얼마나 향상되었는지 각 등급별로 파악할 수 있음
	- 임의로 나눈 각 등급(decile)별로 반응 검출률, 반응률, Gain(이득), Lift(향상도) 등의 정보를 산출하여 나타내는 표
	
	* 기본향상도(baseline lift) = 전체 반응수 / 전체 데이터개수
	* 향성도(lift) = 반응률 / 기본향상도

* 향상도 차트 (lift Chart)
	- 랜덤 모델과 비교하여 해당 모델의 성과가 등급별로 얼마나 향상되었는지 시각적으로 파악할 수 있음
	- 향상도 차트 상에 랜덤과 해당 모델의 life Curve 표시
	- X축 : 모집단의 비율	| - Y : 향상도(lift)
	- 좋은 모델 : Lift Curve가 빠른 속도로 감소 추세를 보임
	- 나쁜 모델 : Lift Curve가 들쭉날쭉하거나 차이를 보이지 않음

	


>>> [ 군집분석 - 계층적 군집 ] 9:45

* 군집분석의 종류
	- 여러 변수 값들로부터 n개의 개체를 유사한 성격을 가지는 몇 개의 군집으로 집단화하고 형성된 군집들의 특성을 파악해 군집들 사이의 관계를 분석하는 다변량분석 기법
	1) 계층적 군집 - 응집형(Agglomerative, Bottom - up), 분리형(Divisive, Top-Down)
	2) 분할적 군집 - 프로토타입-기반, 분포기반, 밀도기반

* 군집간 거리 척도/연결법(Linkage method)
	* 응집형 - 단일(최단) 연결법, 완전(최장) 연결법, 평균 연결법, 중심 연결법, Ward 연결법
	* 분리형 - 다이아나 방법(DIANA Method)
	* 프로토타입-기반 - k-중심 군집(k-평균 군집, k-중앙값 군집, k-메도이드 군집), 퍼지(Fuzzy) 군집
	* 분포기반 - 혼합분포 군집
	* 밀도기반 - 중심밀도 군집, 격자기반 군집

* 계층적 군집 분석의 특징
	- 가장 유사한 개체를 묶어 나가는 과정을 반복하여 원하는 개수의 군집을 형성하는 방법
	- 유사도 판단은 두 개체 간의 거리에 기반하므로 거리 측정에 대한 정의가 필요함
		=> 유클리드, 맨해튼, 민코프스키, 마할라노비스 등
	- 이상치에 민감함
	- 사전에 군집 수 k를 설정할 필요가 없는 탐색적 모형
	- 군집을 형성하는데 매 단계에서 지역적 최적화를 수행해 나가는 방법을 사용하므로 그 결과가 전역적인 최적해라고 볼 수 없음
	- 병합적 방법에서 한 번 군집이 형성되면 군집에 속한 개체는 다른 군집으로 이동할 수 없음
	- hclust()함수, cluster 패키지의 agnes(), mclust() 함수 사용

* 계층적 군집 - 응집형(병합 군집) 군집 방법
	1) 최단 연결법 : 단일연결법이라고도 하며, 두 군집 사이의 거리를 군집에서 하나씩 관측 값을 뽑았을 때 나타날 수 있는 거리의 최솟값을 측정, 고립된 군집을 찾는데 중점을 둔 방식
	2) 최장 연결법 : 완전연결법이라고도 하며, 두 군집 사이의 거리를 군집에서 하나씩 관측 값을 뽑았을 때 나타날 수 있는 거리의 최대값을 측정
	3) 중심 연결법 : 두 군집의 중심 간의 거리를 측정함. 두 군집이 결합될 때 새로운 군집의 평균은 가중평균을 통해 구해짐
	4) 와드 연결법 : 계층적 군집내의 오차제곱합에 기초하여 군집을 수행하는 군집 방법, 크기가 비슷한 군집끼리 병합하는 경향이 있음
	5) 평균 연결법 : 모든 항목에 대한 거리 평균을 구하면서 군집화, 계산양이 많이질 수 있음

* 계층적 군집의 거리
	1) 수학적인 거리 개념 : 유클리드 , 맨해튼, 민코프스키
	2) 통계적 거리 개념 : 표준화, 마할라노비스

	* 유클리드 : 두 점 사이의 가장 직관적이고 일반적인 거리의 개념, 방향성이 고려되지 않음 /
	* 맨해튼 : 두 점의 각 성분별 차의 절대값 합 L
	* 민코프스키 : 거리 차수와 함께 사용되며, 일반적으로 사용되는 거리의 차수는 1, 2, 무한대 )
		- q=2이면 유클리드, q=1이면 맨해튼
	* 표준화 거리 : 각 변수를 해당 변수의 표준편차로 척도 변환한 후에 유클리드 거리를 계산하는 것으로 통계적거리라고도 함
		- 표준화를 하면 척도의 차이, 분산의 차이로 인한 왜곡을 피할 수 있음
	* 마할라노비스 : 변수의 표준화와 함꼐 변수 간의 상관성을 동시에 고려한 통계적 거리
	* dist() 함수 : 거리측정에 사용하는 함수로 사용가능한 거리 개념으로 유클리드, 맨해튼, 민코프스키, maximum, Canberra(가중치 있는 맨해튼 거리), binary 등이 있음
	* 코사인 거리 : 두 백터 사이의 사잇각을 계산해서 유사한 정도를 구하는 것
		- 값이 1인 경우 유사도가 크며, -1인 경우 유사도가 매우 작음을 의미함




>>> [ 군집분석 - 비계층적 군집 ] 8:26

* 비계층적 군집 - 분할적 군집 방법 => k-중심 군집
* k-mean
	- k-mean 방법은 사전에 군집의 수 k를 정해 주어야함(k : hyper parameter)
	* hyper parameter : 사용자가 사전에 정해주어야 하는 값
	- 군집수 k가 원데이터 구조에 적합하지 않으면 좋은 결과를 얻을 수 없음
	- 알고리즘이 단순하며 빠르게 진행되어 계층적 군집보다 많은 양의 자료를 처리
	- k-mean 군집은 잡음이나 이상값에 영향을 받기 쉬움
	- k-mean 분석 전에 이상값을 제거하는 것도 좋은 방법
	- 평균 대신 중앙값을 사용하는 k-medoids 군집을 사용할 수 있음

* k-mean 절차
	1) 초기 군집의 중심으로 k개의 객체를 임의로 선택한다
	2) 각 자료를 가장 가까운 군집의 중심에 할당한다
	3) 각 군집 내의 자료들의 평균을 계산하여 군집의 중심을 갱신한다
	4) 군집 중심의 변화가 거의 없을 때까지 2, 3을 반복한다.

* DBSCAN 
	- 밀도 기반 클러스터링으로 점이 세밀하게 몰려있어 밀도가 높은 부분을 클러스터링 함
	- 어느 점을 기준으로 반경 내에 점이 n개 이상 있으면 하나의 군집으로 인식하는 방식
	- Gaussian 분포가 아닌 임의적 모양의 군집분석에 적합함
	- k 값을 정할 필요 없음, outlier에 의한 성능 하락을 완화할 수 있음

* 혼합분포 군집
	- 데이터가 봉우리가 2개인 분포, 도넛형태의 분포 등 복잡한 형태를 가진 분포의 경우 여러분포를 확률적으로 선형 결합한 혼합분포로 설명될 수 있음
	- 데이터가 k개의 모수적 모형의 가중합으로 표현되는 모집단 모형에서 나왔다는 가정하에, 추정된 k 개의 모형 중 어느 모형으로부터 나왔을 확률이 높은지에 따라 군집 분류를 수행
	- 모수와 가중치 추정에 EM 알고리즘이 사용됨 (Expectation Maximization)

* EM 알고리즘 
	1) 모수(평균, 분산, 혼합계수)에 대해 임의의 초기값을 정함
		* 잠재변수 : 어느 집단에 속하는지에 대한 정보를 갖는 변수
	2) E step : k 개의 모형 군잡에 대해 모수를 사용해 각 군집에 속할 사후확률을 구함
	3) M step : 사후확률을 이용해 최대 우도 추정으로 모수를 다시 추정하고, 이를 반복함

* 군집화 평가 지수
* 실루엣 계수(Silhouette Coefficient)
	- 군집내 거리와 군집 간의 거리를 기준으로 군집 분할 성과를 측정하는 방식
	- 클러스터 안에 데이터들이 다른 클러스터와 비교해 얼마나 비슷한가를 나타내는 군집평가
	- 실루엣 지표가 1에 가까울수록 군집화가 잘 되었다고 판단
	- 실루엣 지표가 1 : 한 군집의 모든 개쳬가 한치도 떨어져 있지 않고 붙어 있는 경우
	- 실루엣 지표가 0.5 보다 크면 결과가 타당하다고 판단

* Dunn Index(DI)
	- DI = 군집과 군집 사이 거리 중 최솟값 / 군집 내 데이터들 거리 중 최댓값
	- 분자가 클수록 군집 간의 거리가 멀고, 분모가 작을 수록 군집 내 데이터가 모여 있음
	- Dunn Index(DI) 클수록 군집화가 잘 되었다고 판단




>>> [ 군집분석 문제 풀이 ] 10:07
Q. 변수의 표준화와 함께 변수 간의 상관성을 동시에 고려한 통계적 거리를 "마할라노비스"라고 한다
Q. 민코프스키 : 거리 차수를 사용하며 거리차수가 1인 경우 맨허튼, 2인 경우 유클리드 거리고 사용됨
Q. 표준화 거리 : 각 변수를 해당 변수의 표준편차로 척도 변환한 후에 유클리드 거리를 계산한 것으로 "통계적 거리"라고도 함
Q. 비계층적 군집분석 기법의 경우 사용자가 사전 지식 없이 그룹의 수를 정해주는 일이 많기 때문에 결과가 잘 나오지 않을 수 있다
Q. 군집분석은 신뢰성과 타당성을 점검하기 어렵디(비지도학습)
Q. 군집 결과에 대한 안정성을 검토하는 방법으로 실루엣, DI를 사용함




>>> [ 군집분석 - SOM(Self Organizing Map) ] 6:54

* SOM (Self - Organizing Maps)
* SOM 이란?
	- 자기조직화지도
	- 인공신경망의 한 종류로, 차원축소와 군집화를 동시에 수행하는 기법
	- 비지도 학습의 한가지 방법
	- 고차원으로 표현된 데이터를 저차원으로 변환해서 보는데 유용함
	- 입력층과 2차원의 격자 현태의 경쟁층으로 이루어져 있음 (2개의 층으로 구성)
	* 인공신경 (=노드), 연결강도(weight)

* SOM Process 
	1) SOM 의 노드에 대한 연결강도 초기화
	2) 입력 벡터와 경쟁 층 노드 간의 거리 계산 및 입력벡터와 가까운 노드 선택 -> 경쟁
	3) 경쟁에서 선택된 노드와 이웃 노드의 가중치(연결강도) 갱신 -> 협력 및 적응
	4) 단계 2로 가서 반복
	-> 승자만이 출력을 내고, 승자와 그 이웃만이 연결강도를 수정하는 승자 독점 구조로 인해 경쟁층에는 승자 뉴런만 나타남

* SOM vs 신경망 모형
	- 신경망 모형은 연속적인 층으로 구성된 반면, SOM은 2차원 그리드(격자)로 구성
	- 신경망 모형은 에러 수정을 학습하는 반면, SOM은 경쟁학습 실시
	- 신경망은 역전파 알고리즘이지만, SOM은 전방패스를 사용해 속도가 매우 빠름

Q. SOM은 "군집분석"
Q. 로지스틱 회귀분석, 신경망, 의사결정 나무는 "분류분석"에 해당한다



>>> [ 연관분석 - ( 지지도, 신뢰도, 향상도 ) ] 10:52

* 연관분석(Association Analysis)
	- 연관분석 : 항목들 간의 '조건-결과'삭으로 표현되는 유용한 패턴
	- 이러한 패턴 규칙을 발견해내는 것을 연관분석이라고 함
	- 장바구니 분석이라고 함(미국 마트에서 기저귀를 사는 고객은 맥주를 동시에 구매한다는 연관규칙을 알아낸 것에 기인함)

* Aprioti 알고리즘
	- 연관규칙의 대표적 알고리즘으로 현재도 많이 사용됨
	- 데이터들에 대한 발생 빈도를 기반으로 각 데이터 간의 연관관계를 밝히는 방법
	- 데이터셋이 큰 경우 모둔 후보 itemset에 대해 하나하나 검사하는 것이 비효율적임

* FP Growth 
	- Apriori 단점을 보안하기 위해 FP-tree와 node, link라는 특별한 자료 구조를 사용

* 연관분석의 장/단점
	* 장점
		- 조건반응으로 표현되는 연관분석의 결과를 이해하기 쉬움
		- 강력한 비목적성 분석 기법이며, 분석 계산이 간편함
	* 단점 	
		- 분석 품목 수가 증가하면 분석 계산이 기하급수적으로 증가함
		- 너무 세분화된 품목을 가지고 연관규칙을 찾으려면 의미 없는 분석결과가 도출됨
		- 상대적 거래량이 적으면 규칙 발견 시 제외되기 쉬움

* 연관규칙 측정 지표
	- 규칙표기 A -> B 	: if A then B => A가 팔리면 B가 같이 팔린다
	* 지지도(Support)
		- 전체 거래 중 차지하는 비율을 통해 해당 연관 규칙이 얼마나 의미가 있는 것인지를 확인함
		- 전체 거래항목 중 상품 A와 상품 B를 동시에 포함하여 거래하는 비율
		- 지지도 = P(A^B) : A와 B가 동시에 포함된 거래수 / 전체 거래수
	* 신뢰도(Confidence) 
		- 상품 A를 구매했을 때 상품 B를 구매할 확률이 어느 정도 되는지를 확인
		- 상품 A를 포함하는 거래 중 A와 B가 동시에 거래되는 비율
		- 신뢰도 = P(B|A) = P(A^B) / P(A) : A와 B가 동시에 포함된 거래 수 / A가 포함된 거래 수
	* 향상도(lift)
		- A가 주어지지 않았을 때 B의 확률 대비 A가 주어졌을 때 B의 확률 증가 비율
		- 품목 B를 구매한 고객 대비 품목 A를 구매한 후 품목 B를 구매하는 고객에 대한 확률
		- 향상도 = P(B|A) / P(B) = P(A^B) / (P(A)*P(B))
		=> 상품 A의 거래 중 상품 B가 포함된 거래의 비율 / 전체 상품 거래 중 상품 B가 거래된 비율
		=> A와 B가 동시에 일어난 확률 / A, B가 독랍된 사건일 때 A, B가 동시에 일어날 확률

* 향상도 해석
	- 향상도가 1인 경우, 품목 A와 B 사이에 아무런 상호관계가 없음(독립)
	- 향상도가 1보다 큰 수 , 높아질수록 연관성이 높다고 할 수 있고, 결과를 예측하는데 우수, 서로 양관 관계로 품목 B를 구매할 확률보다 품목 A를 구매한 후 품목 B를 구매할 확률이 높다는 것을 의미함
	- 향상도가 1보다 작은 수 , 두 품목이 서로 음의 상관관계임을 의미함




>>> [ 연관분석 문제풀이 ] 14:49








>>> 특강8. [ 데이터의 분류, 머신러닝의 분류 ] 28:38

>>> 특강9. [ 계층적 군집의 예(최단연결법) ] 7:06

>>> 특강10. [ 계층적, 비계층적 군집 코드 작성으로 이해 ] 10:41

>>> 특강11. [ 의사결정나무, 불순도 측정, 분류모델 평가 ] 8:13

>>> 특강12. [ 계층적 군집, 군집분석 결과, 군집, 분류 분석의 구분 ] 6:19
 










