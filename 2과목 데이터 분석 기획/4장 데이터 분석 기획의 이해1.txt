👩🏻‍💻 2과목 데이터 분석 기획

4장. 데이터 분석 기획의 이해
	01. 분석 기획 방향성 도출
	02. 분석 방법론
	----------------------
	03. 분석 과제 발굴
	04. 분석 프로젝트 관리 방안

4-1) 48~67 numbering object
4-2) 68~83 numbering object


48. 분석 주제 유형
- 분석의 대상(what) 및 분석의 방법(how)에 따라 4가지 유형으로 구분
1) Optimization(최적화) : 분석 대상 및 분석 방법을 이해하고 현 문제를 푀적화의 형태로 수행
2) Solution(솔루션) : 분석 과제는 수행되고, 분석 방법을 알지 못할 경우 솔루션을 찾는 방식으로 분석 과제수행
3) Insight(통철력) : 분석 대상이 불분명하고, 분석 방법을 알고 있는 경우 인사이트 도출
4) Discovery(발견) : 분석 대상, 방법을 모른다면 발견을 통하여 분석 대상 자체를 새롭게 도출

- 분석의 주제 및 기법의 특성상 이러한 4사지 유형은 서로 융합적으로 반복하게 됨



49. 목표 시점별 기획 방안
- 과제 중심적인 접근 방안 : 당면한 과제를 빠르게 해결
- 장기적인 마스터플랜 방식 : 지속적인 분석 내재화로 해결
--------------------------------------------------------
당먄한 분석 주제 해결	|		| 지속적 분석문화 내재화
--------------------------------------------------------
과제 단위		| 		| 마스터 플랜 단위
--------------------------------------------------------
Speed & Test	| < 1차 목표 >	| Accuracy & Deploy
--------------------------------------------------------
Quick - Win	| < 과제의 유형 >	| Long Term View
--------------------------------------------------------
Problem Solving	| < 접근 방식 >	| Problem Definition	
--------------------------------------------------------

* 출제유형
과제단위와 마스터플랜단위 구분 문제 출제



50. 분석기획 시 고려사항
1) 가용한 데이터 ( Available Data ) 
데이터 유형에 따라서 적용 가능한 솔루션 및 분석 방법이 달라서 유형에 대한 분석이 선행적으로 이루어져야 한다.

2) 적절한 유스케이스 ( Proper Use-Case )
탐색 유사 분석 시나리오 및 솔루션이 있다면 최대한 이를 활용하는 것이 중요함

3) 장애요소들에 대한 사전 계획 수립이 필요



51. 데이터 저장 방식
-----------------------------------------------------------------------
저장방식	| 특징					| 도구
-----------------------------------------------------------------------
RDB	| 관계형 데이터를 저장하거나 수정하고 관리	할 수 있게	| Oracle
	| 해주는 데이터베이스				| MSSQL
	| SQL 문장을 통하여 DB의 트랜잭션 서비스 제공	| MySQL 등
-----------------------------------------------------------------------
NoSQL	| NoSQL DB = 비관계형(비정형) DBMS		| Mongo DB
	| NoSQL은 빅데이터 분산처리 및 저장기술과 함께	| Cassandra
	| 발달된 분산 DB기술로 확장성 및 가용성을 제공한다.	| HBase
	| 대용량 처리와 대규모의 수평적 확장성 제공한다.	| Redis
-----------------------------------------------------------------------
HDFS	| HDFS와 기존의 대용량 파일 시스템의 큰 차이점은	| HDFS 등
	| HDFS는 저사향 서버를 이용해 스토리지를 구성 가능	|
-----------------------------------------------------------------------
-> 기존의 대용량 파일 시스템 또는 DB를 구성하려면 고성능의 서버나 대용량 외장 스토리지가 필요하였으며 이러한 시스템은 웹 서버와 같ㅌ은 서버에 비해 상당히 많은 비용이 발생하게 됩니다.
하지만 HDFS를 이용하면 수십 혹은 수백 대의 웹 서버급 서버나 저사양 서버를 묶어서 하나의 스토리지 처럼 사용할 수 있게 됩니다.
( 하둡 -> HDFS, MapReduce )

* 출제유형
NoSQL과 RDBMS 저장 도구 종류 구분이 출제



52. 기업의 합리적 의사결정 장애 요소
1) 고정관념 ( Stereotype )
2) 편향된 생각 ( Bias )
3) 프레이밍 효과 ( Framing Effect )
- 문제의 표현 방식에 따라 같은 사건이나 상황임에도 불구하고 개인의 판단이나 선택이 달라질 수 있는 현상

-> 데이터 기반의 의사결정을 위해서는 기업문화의 변화와 업무 프로세스 개선이 필요



53. 분석 방법론의 구성 요소
1) 상세한 절차 ( Procedure )
2) 방법 ( Method )
3) 도구와 기법 ( Tool & Techniques )
4) 템플릿과 산출물 ( Templates & Outputs )로 구성



54. 폭포수 / 나선형 / 프로토타입 모델
-> 분석 방법론을 통해서 해당되는 적용에 따라서 다양한 모형이 만들어진다.
1) 폭포수( Waterfall ) 모델
- 단계별로 철저한 검토와 승인 과정을 거쳐 확실이 매듭짓고 다음 단게로 진행하는 모델
- 하향식(Top Down) 진행되지만, 문제나 개선사항이 발견되면 전단계로 돌아가는 피드백 과정 수행

2) 나선형( Spiral ) 모델
- 여러 번의 개발 과정을 거쳐 점진적으로 프로젝트를 완성해나가는 모델
- 처음 시도하는 프로젝트에 적용이 용이, 반복에 대한 관리체계를 효과적으로 갖추지 못한 경우 프로젝트 진행이 어렵다
- 대규모 시스템 소프트웨어 개발에 적합하다.

3) 프로토타입( ProtoType ) 모델
- 사용자가 요구사항이나 데이터를 정확히 규정하기 어렵고 데이터 소스도 명확히 파악하기 어려운 상황에서 일단 분석을 시도해 보고
그 결과를 확인해 가면서 반복적으로 개선해 나가는 방법
- 프로토타이핑 모델은 요구사항을 분석한 후 프로토타입을 개발하여, 평가를 받는다.
평가 결과에 따라 개발 실행 또는 프로토타입 개선이나 요구사항을 재분석한다.
폭포수 모델의 피드백에 대한 어려움을 보안하기 위해 프로토타이핑 제작과 평과 추가함 



55. KDD 분석 방법론
- KDD ( Knowledge Discovery in Database )는 1996년 Fayyad가 체계적으로 정리한 데이터마이닝 프로세스로서 
데이터베이스에서 의미 있는 지식을 탐색하는 데이터 마이닝, 기계학습, 인공지능, 패턴인식, 데이터 시각화 등에서 응용될 수 있는 구조를 갖추고 있다.



56. KDD 분석 절차
1) 분석 대상의 비즈니스 도메인에 대한 이해와 프로젝트 목표를 정확하게 설정
2) 데이터 세트 선택 ( Selection )
3) 데이터 전처리 ( Preprocessing ) : 분석 데이터 세트에 포함된 잡음(Noise), 이상값(Outlier), 결측치(Missing value)를 식별하고 필요할 때 제거한다.
4) 데이터 변환 ( Transformation ) : 분석 목적에 맞는 변수를 선택하거나 데이터의 차원을 축소하여 데이터마이닝을 효율적으로 적용할 수 있도록 데이터 셋을 변경한다.
5) 데이터 마이닝( Data Mining ) : 변환된 데이터 세트를 이용하여 분석 목적에 맞는 데이터 마이닝 기법을 선택하고, 데이터 마이닝 알고리즘을 선택하여 데이터의 패턴을 찾거나 데이터를 분류 또는 예측하는 등의 마이닝 작업을 시행한다.
6) 데이터 마이닝 결과 평가 ( Interpretation / Evalution) : 분석 결과에 대한 해석과 평과 그리고 활용을 한다.



57. CRISP-DM 분석 방법론
CRISP-DM ( Cross Industry Standard Process For Data Mining )
- 프로세스는 6단계로 구성되어 있으며, 각 단계는 폭포수 모델처럼 한 방향으로 구성되어 있지 않고 단계 간 피드백을 통하여 완성도를 높이게 됨
- 한번에 끝낼 수는 없다. 반복해야하기 때문에
> CRISP-DM Process
1) Business Understanding <-> 2) Data Understanding -> 3) Data Preparation <-> 4) Modeling 
	-> 5) Evaluation -> 6) Deployment
			 -> 1) Business Understanding

* 출제유형
화살표의 양방향(피드백)이 형성되는 구간이 출제



58. CRISP-DM 분석 절차
구조의 형태 : 단계 페이스 => 일반화 테스크 -> 세분화 테스트 -> 프로세스 인스턴스

1) 업무 이해 ( Business Understanding )
	- 비즈니스 관점 프로젝트의 목적과 요구 사항을 이해하기 위한 단계
	- 도메인 지식을 데이터 분석을 위한 문제 정의로 변경하고 초기 프로젝트 계획을 수립하는 단계
	=> 업무 목적 파악, 상황 파악, 데이터 마이닝 목표설정, 프로젝트 계획 수립으로 구성

2) 데이터 이해 ( Data Understaing )
	- 데이터 이해는 분석을 위한 데이터를 수집하고 데이터 속성을 이해하기 위한 과정으로 구성되고, 
	데이터 품질에 대한 문제점을 식별하고 숨겨져 있는 인사이트를 발견하는 단계
	=> 초기 데이터 수집, 데이터 기술 분석, 데이터 탐색, 데이터 품질 확인

3) 데이터 준비 ( Data Preparation ) 
	- 데이터 준비는 분석을 위하여 수집된 데이터에서 분석 기법에 적합한 데이터 세트를 편성하는 단계로 많은 시간이 소요될 수 있음
	=> 분석용 데이터 세트 선택, 데이터 정제, 데이터 통합, 데이터 포멧팅이 해당

4) 모델링 ( Modeling )
	- 다양한 모델링 기법과 알고리즘을 선택하고 모델링 과정에서 사용 파라미터를 최적화해 나가는 단계
	- 이 단계를 통해 찾아낸 모델은 테스트용 프로세스와 데이터셋을 평가하여 모델 과대적합(Overfitting) 등의 
	문제를 발견하고 대응방안을 마련함
	=> 모델링 기법 선택, 모델 테스트 계획 설계, 모델 작성, 모델 평가로 구성

5) 평가 ( Evaluation )
	- 프로젝트의 목적에 부합하는지 모델 평가
	- 데이터 마이닝 결과 수용 여부를 최종적으로 판단
	=> 분석 결과 평가, 모델링 과정 평가, 모델 적용성 평가

6) 전재 ( Deployment )
	- 모델링과 평가 단계를 통하여 완성된 모델을 실제 업무에 적용하기 위한 계획을 수립하고 모니터링과 모델의 유지보수 계획 마련
	=> 전재 계획 수립, 모니터링과 유지보수 계획 수립, 프로젝트 종료 보고서 작성, 프로젝트 검토로 구성



59. 계층적 프로세스 모델 3계층 구성		Mapping
단계 ( Phase ) <-- Process Group -- [ 태스크 ( Task ) ] -- Unit Process --> 스탭 ( Step )
- SOW, WBS
- 용어정리
Q. WBS ( Work Breakdown Structure: 작업 분할 구조도)는 무엇인가 ?
	A. Project Management에 이용되는 기법의 하나로 프로젝트 전체를 작은 작업 단위로 분할한 구성도, 
	사전적인 의미로는 프로젝트의 범위와 최종 산출물을 세부요소로 분할한 계층적 구조도라고 정의함

Q. SOW( Statement Of Work, 작업 기술서 = 작업 지시서 )
	A. 고객의 요구사항 및 프로젝트의 결과 등을 상세히 기술해 놓은 명세서



60. 빅데이터 분석 방법론
-----------------------------------------------------------------------------------------
Planning		| Preparing	| Analyzing	| Developing	| Deploying
-----------------------------------------------------------------------------------------
분석 기획			| 데이터 준비	| 데이터 분석	| 시스템 구현	| 평가 및 전개
-----------------------------------------------------------------------------------------
비즈니스 이해 및 범위 설정	| 필요 데이터 정의	| 분석용 데이터 준비	| 설계 및 구현	| 모델 발전 계획
-----------------------------------------------------------------------------------------
프로젝트 정의 및 계획 수립	| 데이터 스토어 설계	| 텍스트 분석	| 시스템 테스트&운영	| 프로젝트 평가 보고
-----------------------------------------------------------------------------------------
프로젝트 위험 계획 수립	| 데이터 수집 및 	| 탐색적 분석	| 		| 평가 및 전개
			| 적합성 점검	|		|		|	
-----------------------------------------------------------------------------------------
			|		| 모델링		|		|
-----------------------------------------------------------------------------------------				|		| 모델 평가 및 검증	|		|
-----------------------------------------------------------------------------------------

- 분석 단계를 수행하는 과정에서 추가적인 데이터 확보가 필요한 경우 데이터 준비단계로 피드백 가능
- 데이터 분석 단계에서 프로토타입 시스템을 구현하고자 하는 경우 시스템 구현 단계를 수행

* 출제유형
빅데이터 분석 방법론 단계 - 태스크 - 스텝으로 구분하고 순서와 해당 단계의 태스크까지 알고 있어야 합니다.



61. 분석 기획 ( Planning ) : Phase 해당
1) 비즈니스 이해 범위 설정 : task 해당
	- 비즈니스 이해 : 내부 업무 메뉴얼과 관련 자료, 외부 관련 자료 비즈니스 자료 조사 향후 프로젝트 방향 설정
	- 프로젝트 범위 설정 : 비즈니스 이해와 프로젝트 목적에 부합되는 범위 설정 : step 해당
		-> SOW : project manager 프로젝트 수행 전에 개념정리 기회 제공
		프로젝트 팀원들에게 한눈에 프로젝트 전체를 볼 수 있게 하고, 진행 도중 새롭게 투입된 팀원에게 전달하기 위해 작성

2) 프로젝트 정의 및 계획 수립 : task 해당

3) 프로젝트 위험 계획 수립 : task 해당
	- 계획 수립 단계에서 빅데이터 분석 프로젝트를 진행하면서 발생 가능한 모든 위험을 발굴하여 사전에 대응방안 수립
	- 위험 대응 계획 수립 예상되는 위험에 대한 대응은 회피(avoid), 전이(transfer), 완화(mitigate), 수용(accept) 
	  구분하여 관리 계획서를 작성
	- 리스트는 제거하는 것이 아니라 일정 수준 이하로 낮추는 것
	
* 용어정리
- 회피 ( Avoidance ) : 발생원인 제거하는 것
- 전가 ( Transfer ) : 제 3자에게 이전, 보험, 보증
- 완화 ( Mitigation ) : 용인 가능한 임계치까지 관리
- 수용 ( Acceptance ) : 실제 발생 시 대응, 리스트가 발생하기 전에 어떤 조치도 취하지 않는 것



62. 데이터 준비 ( Preparing ) : phase
1) 필요 데이터 정의 : task
	=> 데이터 정의서를 만드는 단게 ( 어떤 형의 데이터를 준비할 것인지 알아야 하므로 )
2) 데이터 스토어 설계 : task
	- 정형 데이터 스토어 설계
	- 비정형 데이터 스토어 설계
3) 데이터 수집 및 정합성 점검 ( 품질 이상 없는지 확인 )



63. 데이터 분석 ( Analyzing )
1) 분석용 데이터 준비 ( ETL이나 도구를 통해서 갖고와서 표준화된 데이터 구조 형태로 만든다)
2) 텍스트 분석 ( 비정형 데이터 분석 )
3) 탐색적 분석
	- 다양한 데이터 시각화를 활용하여 데이터의 가독성을 명황히 하고 데이터의 형상 및 분포 등 데이터 특성 파악


64. 데이터 분석 ( Analyzing ) : phase >>> 모델링 ( Modeling ) : task
- 모델링이란 분석용 데이터를 이용한 가설 설정을 통해 통계 모델을 만들거나 기계학습을 이용항 데이터 분류, 예측, 군집 등의
기능을 수행하는 모델을 만드는 과정을 말한다.

- 데이터 분할 : 모델의 과적합과 일반화를 위해 분석용 데이터셋을 모델, 개발을 위한 훈련용 데이터와 모델의 검증력을 테스트하기 위한 데이터로 나눈다.
- 데이터 모델링 : 기계학습을 이용한 데이터 모델링은 훈련용 데이터를 활용하여 분류 또는 예측, 군집 등의 모델을 만들어 가동중인 운영 시스템에 적용한다.
	또한 필요 시 비정형 데이터 분석 결과를 통합적으로 활용하여 프로젝트 목적에 맞는 통합 모델링을 수행한다.
	( 처리 및 도구 ) - 통계 모델링 기법, 기계학습
	( 출력 자료 ) - 모델링 결과 보고서

- 모델 적용 및 운영 방안 : 모델을 가동중인 운영시스템에 적용하기 위해서는 모델에 대한 상세한 알고리즘 작성이 필요하다.
	알고리즘 설명서는 시스템 구현 단계에서 중요한 입력자료로 활용되므로 필요 시 의사코드 수준의 상세한 작성이 필요할 수 있다.

* 용어정리
의사코드 : 일반적인 언어로 코드를 흉내 내어 알고리즘을 써놓은 코드, 특정 언어로 프로그램 작성하기 전에 알고리즘의 모델을 대략적으로 모델링할 때 사용



65. 데이터 분석 ( Analyzing ) : phase >>> 모델 평가 및 검증 : task
- 모델 평가 : 모델 평가를 위해서는 모델 결과 보고서 내의 알고리즘을 파악하고 테스트용 데이터나 필요시 모델 검증을 위한 별도의 데이터를 활용할 수 있다.

- 모델 검증 : 검증용 데이터는 모델 개발 및 평가에 활용된 훌련용 데이터나 테스트용 데이터가 아닌 실제 운영용 데이터를 확보하여 모델의 품질을 최종 검증하는 프로세스


66. 시스템 구현
분석 기획의 의도에 맞는 모델을 데이터 분석 단계를 진행하여 도출하고 이를 운영중인 시스템에 적용하거나 프로토타입을 구현하고자 하는 경우 시스템 구현 단계를 진행한다. 단순한 데이터 분석이나 데이터 마이닝을 통한 분석 보고서를 작성하는 것으로 프로젝트가 종료되는 경우에는 시스템 구현 단계를 수행할 필요가 없고 다음 단계인 평가 및 전개 단계를 수행한다.

1) 설계 및 구현 - ( 시스템 분석 및 설계, 시스템 구현 )
2) 시스템 테스트 및 운영 - ( 시스템 테스트, 시스템 운영 계획 )



67. 평가 및 전개
1) 모델 발전 계획 수립
	- 모델 발전 계획 수립

2) 프로젝트 평가 및 보고
	- 프로젝트 성과 평가
	- 프로젝트 종료 ( 프로젝트 최종 보고서 작성 )



